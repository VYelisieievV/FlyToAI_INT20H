{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nfrom sklearn import preprocessing\n\nimport lightgbm as lgb\n\nfrom keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\n\nimport tensorflow as tf\nnp.random.seed(42)\ntf.random.set_seed(1)\n\nfrom tensorflow.keras.layers import Input, Embedding, SpatialDropout1D, LSTM, Dropout, Dense\nfrom tensorflow.keras.layers import Concatenate,Flatten,Reshape, Bidirectional\nfrom tensorflow.keras.models import Model\n\nfrom sklearn.model_selection import train_test_split\n\npd.options.mode.chained_assignment = None","execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH = '/kaggle/input/predictingbookratingsint20h/'\ndata = pd.read_csv(PATH+'train.csv').drop(columns = 'id')\ntest = pd.read_csv(PATH+'test.csv').drop(columns = 'id')\nsubmission = pd.read_csv(PATH+'submission.csv')","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_sep(data_):\n    data_.book_authors = data_.book_authors.fillna('')\n    data_.book_authors = data_.book_authors.apply(lambda x: x.split('|'))\n    \n    data_.book_genre = data_.book_genre.fillna('')\n    data_.book_genre = data_.book_genre.apply(lambda x: x.split('|'))\n    \n    return data_\n\ndata = split_sep(data)\ntest = split_sep(test)\n\ndef top5(data_):\n    data_['book_genre'] = data_['book_genre'].apply(lambda x: x[:5]  )\n    data_['book_authors'] = data_['book_authors'].apply(lambda x: x[0])\n    \n    return data_\n\ndata = top5(data)\ntest = top5(test)\n\ndef pp_format_pages(data_):\n    \n    data_[\"book_format\"] = data_[\"book_format\"].fillna(\"no_format\")\n    #fill nan with mean over format\n    data_[\"book_pages\"].loc[~data_[\"book_pages\"].isnull()] = (\n        data_[\"book_pages\"].loc[~data_[\"book_pages\"].isnull()].apply(lambda x: int(x[:-5]))\n    )\n    data_[\"book_pages\"] = data_[\"book_pages\"].astype(np.float32)\n    data_[\"book_pages\"] = data_[\"book_pages\"].fillna(\n        data_.groupby(\"book_format\")[\"book_pages\"].transform(\"mean\")\n    )\n    data_[\"book_pages\"] = data_[\"book_pages\"].fillna(0)\n    data_[\"book_pages\"] = data_[\"book_pages\"].astype(np.int32)\n    \n    return data_\n\ndata = pp_format_pages(data)\ntest = pp_format_pages(test)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('test book_rating_count 5% - ', test.book_rating_count.quantile(0.05))\nprint('Will lose', data[data.book_rating_count <= test.book_rating_count.quantile(0.05) ].shape[0]/data.shape[0])\n\ndata = data[data.book_rating_count > test.book_rating_count.quantile(0.05)]\ndata.reset_index(drop=True, inplace=True)","execution_count":12,"outputs":[{"output_type":"stream","text":"test book_rating_count 5% -  330.0\nWill lose 0.257875\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('% of common Authors in test',\n    data[data.book_authors.isin(test.book_authors.unique())].shape[0]/data.shape[0])\n\nprint('% of common Authors in train',\ntest[test.book_authors.isin(data.book_authors.unique())].shape[0]/test.shape[0])","execution_count":13,"outputs":[{"output_type":"stream","text":"% of common Authors in test 0.1373420919656392\n% of common Authors in train 0.41754966887417216\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def flat(lst):\n    if isinstance(lst, list):\n        for item in lst:\n            yield from flat(item)\n    else:        \n        yield lst\n\nGenres = set(list(flat(list(test['book_genre']))))\nGenres = {i:ind+1 for ind, i in enumerate(Genres)}\n\nGenres.update({'not_in_test': max(Genres.values())+1})\n\n\nAuthors = set(list(flat(list(test['book_authors']))))\nAuthors = {i:ind for ind, i in enumerate(Authors)}\n\nAuthors.update({'not_in_test': max(Authors.values())+1})\n\nFormat = set(list(flat(list(test['book_format']))))\nFormat = {i:ind for ind, i in enumerate(Format)}\n\nFormat.update({'not_in_test': max(Format.values())+1})\n\n\ndef replace_smth(data_, Dict):\n    L = []\n    if type(data_)==list:\n        for i in data_:\n            if i in Dict.keys():\n                L.append(i)\n            else:\n                L.append('not_in_test')\n        return L\n    else:\n        if data_ in Dict.keys():\n            return data_\n        else:\n            return 'not_in_test'\n    \n\ndef replace_smth_data(data__):\n    data__['book_genre'] = data__['book_genre'].apply(lambda x: replace_smth(x, Genres))\n    data__['book_authors'] = data__['book_authors'].apply(lambda x: replace_smth(x, Authors))\n    data__['book_format'] = data__['book_format'].apply(lambda x: replace_smth(x, Format))\n\n    data__['book_genre'] = data__['book_genre'].apply(lambda x: [Genres[i] for i in x])\n    data__['book_authors'] = data__['book_authors'].apply(lambda x: Authors[x])\n    data__['book_format'] = data__['book_format'].apply(lambda x: Format[x])\n    \n    data__['book_genre'] = list(pad_sequences(data__['book_genre'], maxlen=5, padding='post'))\n\n\n    return data__\n\ndata = replace_smth_data(data)\ntest = replace_smth_data(test)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#data = data[data.book_authors != 'not_in_test']","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install langdetect\nfrom langdetect import detect\n\nfrom tqdm import tqdm\n\ndata = data[~data.book_desc.apply(lambda x: x[:len('http://')]=='http://') ]\ndata.reset_index(drop=True, inplace=True)\n\ndata['language'] = ''\nfor i in tqdm(range(0, data.shape[0], 100)):\n    try:\n        #print(i)\n        data['language'].iloc[i:i+100] = data.book_desc.iloc[i:i+100].apply(lambda x: detect(x[:50]))\n        \n    except:\n        pass\n        \ndata = data[(data['language'] == 'en') | (data['language'] == '')]\ndata.reset_index(drop=True, inplace=True)","execution_count":16,"outputs":[{"output_type":"stream","text":"Collecting langdetect\n  Downloading langdetect-1.0.8.tar.gz (981 kB)\n\u001b[K     |████████████████████████████████| 981 kB 2.8 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from langdetect) (1.15.0)\nBuilding wheels for collected packages: langdetect\n  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.8-py3-none-any.whl size=993190 sha256=4782db8a475d51bd7cdcb439b7f653406eeb89e0bc89cdb5421534d9ef335fe2\n  Stored in directory: /root/.cache/pip/wheels/59/f6/9d/85068904dba861c0b9af74e286265a08da438748ee5ae56067\nSuccessfully built langdetect\n^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\n","name":"stdout"},{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'langdetect'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-8681fe55cebf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install langdetect'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangdetect\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdetect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langdetect'"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"Scaler = preprocessing.MinMaxScaler()\ndata.book_rating = Scaler.fit_transform(data.book_rating.values.reshape(-1,1))\n#test.book_rating = Scaler.transform(test.book_rating.values.reshape(-1,1))\n\nScaler_pag = preprocessing.MinMaxScaler()\ndata.book_pages = Scaler_pag.fit_transform(data.book_pages.values.reshape(-1,1))\ntest.book_pages = Scaler_pag.transform(test.book_pages.values.reshape(-1,1))\n\nScaler_rev = preprocessing.MinMaxScaler()\ndata.book_review_count = Scaler_rev.fit_transform(data.book_review_count.values.reshape(-1,1))\ntest.book_review_count = Scaler_rev.transform(test.book_review_count.values.reshape(-1,1))\n\nScaler_rat = preprocessing.MinMaxScaler()\ndata.book_rating_count = Scaler_rat.fit_transform(data.book_rating_count.values.reshape(-1,1))\ntest.book_rating_count = Scaler_rat.transform(test.book_rating_count.values.reshape(-1,1))","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[['book_genre', 'book_authors', 'book_format', 'book_pages', 'book_review_count', 'book_rating_count', 'book_rating']]","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"                     book_genre  book_authors  book_format  book_pages  \\\n0       [193, 121, 95, 223, 34]          2240            3    0.051973   \n1      [223, 87, 204, 135, 193]          2240            7    0.031806   \n2        [216, 244, 35, 116, 0]          2240            7    0.007173   \n3        [34, 65, 116, 184, 85]          2240            7    0.007444   \n4      [160, 35, 184, 128, 263]          2240            7    0.021385   \n...                         ...           ...          ...         ...   \n29680    [40, 66, 223, 40, 198]          2240            7    0.013535   \n29681        [223, 97, 0, 0, 0]           422            7    0.033227   \n29682     [216, 35, 244, 86, 2]          2240            7    0.003248   \n29683  [97, 223, 193, 121, 176]          2240            7    0.022738   \n29684    [29, 35, 232, 232, 79]          2240           11    0.015159   \n\n       book_review_count  book_rating_count  book_rating  \n0               0.250019           0.121049     0.739300  \n1               0.002059           0.000597     0.571984  \n2               0.000174           0.000007     0.595331  \n3               0.001555           0.000724     0.544747  \n4               0.000578           0.000079     0.673152  \n...                  ...                ...          ...  \n29680           0.000541           0.001177     0.762646  \n29681           0.153387           0.029866     0.832685  \n29682           0.000809           0.000222     0.684825  \n29683           0.004012           0.000475     0.505837  \n29684           0.001356           0.000259     0.704280  \n\n[29685 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>book_genre</th>\n      <th>book_authors</th>\n      <th>book_format</th>\n      <th>book_pages</th>\n      <th>book_review_count</th>\n      <th>book_rating_count</th>\n      <th>book_rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[193, 121, 95, 223, 34]</td>\n      <td>2240</td>\n      <td>3</td>\n      <td>0.051973</td>\n      <td>0.250019</td>\n      <td>0.121049</td>\n      <td>0.739300</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[223, 87, 204, 135, 193]</td>\n      <td>2240</td>\n      <td>7</td>\n      <td>0.031806</td>\n      <td>0.002059</td>\n      <td>0.000597</td>\n      <td>0.571984</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[216, 244, 35, 116, 0]</td>\n      <td>2240</td>\n      <td>7</td>\n      <td>0.007173</td>\n      <td>0.000174</td>\n      <td>0.000007</td>\n      <td>0.595331</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[34, 65, 116, 184, 85]</td>\n      <td>2240</td>\n      <td>7</td>\n      <td>0.007444</td>\n      <td>0.001555</td>\n      <td>0.000724</td>\n      <td>0.544747</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[160, 35, 184, 128, 263]</td>\n      <td>2240</td>\n      <td>7</td>\n      <td>0.021385</td>\n      <td>0.000578</td>\n      <td>0.000079</td>\n      <td>0.673152</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>29680</th>\n      <td>[40, 66, 223, 40, 198]</td>\n      <td>2240</td>\n      <td>7</td>\n      <td>0.013535</td>\n      <td>0.000541</td>\n      <td>0.001177</td>\n      <td>0.762646</td>\n    </tr>\n    <tr>\n      <th>29681</th>\n      <td>[223, 97, 0, 0, 0]</td>\n      <td>422</td>\n      <td>7</td>\n      <td>0.033227</td>\n      <td>0.153387</td>\n      <td>0.029866</td>\n      <td>0.832685</td>\n    </tr>\n    <tr>\n      <th>29682</th>\n      <td>[216, 35, 244, 86, 2]</td>\n      <td>2240</td>\n      <td>7</td>\n      <td>0.003248</td>\n      <td>0.000809</td>\n      <td>0.000222</td>\n      <td>0.684825</td>\n    </tr>\n    <tr>\n      <th>29683</th>\n      <td>[97, 223, 193, 121, 176]</td>\n      <td>2240</td>\n      <td>7</td>\n      <td>0.022738</td>\n      <td>0.004012</td>\n      <td>0.000475</td>\n      <td>0.505837</td>\n    </tr>\n    <tr>\n      <th>29684</th>\n      <td>[29, 35, 232, 232, 79]</td>\n      <td>2240</td>\n      <td>11</td>\n      <td>0.015159</td>\n      <td>0.001356</td>\n      <td>0.000259</td>\n      <td>0.704280</td>\n    </tr>\n  </tbody>\n</table>\n<p>29685 rows × 7 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_genres = np.stack(data.book_genre.values)\nX_authors = data.book_authors.values\nX_book_format = data.book_format.values\nX_book_pages = data.book_pages.values\nX_book_review_count = data.book_review_count.values\nX_book_rating_count = data.book_rating_count.values\n\ny = data.book_rating.values\n\nX_test_genres = np.stack(test.book_genre.values)\nX_test_authors = test.book_authors.values\nX_test_book_format = test.book_format.values\nX_test_book_pages = test.book_pages.values\nX_test_book_review_count = test.book_review_count.values\nX_test_book_rating_count = test.book_rating_count.values","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m = lstm128()","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Here all embed_size\nmax_features_authors = max(Authors.values())+1\nembed_size_authors = 100\n\nmax_features_genres = max(Genres.values())+1\nembed_size_genres = 50\n\nmax_features_format = max(Format.values())+1\nembed_size_format = 5\n\nprint(max_features_authors, max_features_genres, max_features_format)\n\ndef lstm128():\n    \n    inp_gen = Input(shape=(5,), name='genres')\n    inp_aut = Input(shape=(1,), name='authors')\n    inp_for = Input(shape=(1,), name='format')\n    inp_pag = Input(shape=(1,), name='pages')\n    inp_rev = Input(shape=(1,), name='review')\n    inp_rat = Input(shape=(1,), name='rating')\n    \n    inp = [inp_gen, inp_aut, inp_for, inp_pag, inp_rev, inp_rat]\n        \n    seq_gen   = Embedding(max_features_genres, embed_size_genres, name='emb_gen')(inp_gen)\n    seq_aut   = Embedding(max_features_authors, embed_size_authors, name='emb_aut')(inp_aut)\n    seq_for   = Embedding(max_features_format, embed_size_format, name='emb_for')(inp_for)\n    \n    lstm_gen  = LSTM(128, return_sequences=False )(seq_gen  )\n    lstm_aut  = LSTM(128, return_sequences=False )(seq_aut )\n    lstm_for  = LSTM(16, return_sequences=False )(seq_for )\n            \n    x = Concatenate(name=\"x1\")([lstm_gen, lstm_aut,lstm_for, inp_pag, inp_rev, inp_rat])\n\n    x = Dense(128, activation=\"relu\")(x)\n    x = Dropout(0.1)(x)\n    x = Dense(128, activation=\"relu\")(x)\n    x = Dropout(0.1)(x)\n    outp = Dense(1, activation=\"relu\")(x)\n    \n    model = Model(inputs=inp, outputs=outp)\n    \n    model.compile(loss='mse',\n                  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n                 )\n    return model","execution_count":23,"outputs":[{"output_type":"stream","text":"2241 264 15\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def early_stopping_lgb(train_ , valid_, params_, params_stopping_, columns_):\n\n    train_dataset = lgb.Dataset( train_[columns_], label =train_.book_rating, free_raw_data=False)\n    valid_dataset = lgb.Dataset( valid_[columns_], label =valid_.book_rating, free_raw_data=False)\n\n    model = lgb.train(\n        params_,\n        train_dataset,\n        num_boost_round = params_stopping_['num_boost_round'],\n        valid_sets = (train_dataset, valid_dataset) ,\n        early_stopping_rounds = params_stopping_['early_stopping_rounds'],\n        verbose_eval = params_stopping_['verbose_eval'],\n    )\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for gen in range(5):\n    data['gen'+str(gen)] = data.book_genre.apply(lambda x: x[gen])\n    test['gen'+str(gen)] = test.book_genre.apply(lambda x: x[gen])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['pred_lgbm'] = 0\n\nfor Fold, (train_index, valid_index) in enumerate(KFold(n_splits=5, random_state=42, shuffle=True).split(data)):\n    \n    train, valid = data.iloc[train_index], data.iloc[valid_index]\n    \n    print(Fold, train.shape[0], valid.shape[0])\n    \n    \n    columns_lgb = ['book_authors', 'book_format', 'book_pages',\n               'book_review_count', 'book_rating_count', 'gen0', 'gen1', 'gen2', 'gen3', 'gen4']\n\n    params = {'metrics':'l2',\n         'objective':'regression',\n              'num_leaves':256\n             }\n\n    params_stopping = {\n        'num_boost_round':10000,\n        'early_stopping_rounds':100,\n        'verbose_eval':1000}\n    \n    lgbm_train, lgbm_valid = train_test_split(train, random_state=42,shuffle=True, test_size=0.1)\n\n    model = early_stopping_lgb(lgbm_train, lgbm_valid, params, params_stopping, columns_lgb)\n    \n    pred_valid = model.predict(valid[columns_lgb])\n    \n    data['pred_lgbm'].iloc[valid.index] =  Scaler.inverse_transform(pred_valid.reshape(-1,1)).flatten()\n    \n\n    pred = model.predict(test[columns_lgb])\n\n    test['Fold_lgbm_'+str(Fold)] = Scaler.inverse_transform(pred.reshape(-1,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['pred'] = 0\n\nfor Fold, (train_index, valid_index) in enumerate(KFold(n_splits=5, random_state=42, shuffle=True).split(data)):\n    \n    train, valid = data.iloc[train_index], data.iloc[valid_index]\n    \n    print(Fold, train.shape[0], valid.shape[0])\n    \n    \n    model = lstm128()\n\n    es = EarlyStopping( monitor='val_loss',\n                       patience=10)\n\n    reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n                                  factor=0.5,\n                                  patience=10,\n                                  min_lr=0.000001)\n\n    model.fit([X_genres[train.index], X_authors[train.index], X_book_format[train.index],\n               X_book_pages[train.index], X_book_review_count[train.index], X_book_rating_count[train.index]],\n               y[train.index], batch_size=3000, epochs=100, verbose=True,\n               validation_split=0.1, shuffle=True, \n               callbacks=[es,reduce_lr])\n\n\n    pred_valid = model.predict([X_genres[valid.index], X_authors[valid.index], X_book_format[valid.index],\n                  X_book_pages[valid.index], X_book_review_count[valid.index], X_book_rating_count[valid.index]])\n    \n    data['pred'].iloc[valid.index] =  Scaler.inverse_transform(pred_valid).flatten()\n    \n    \n    \n    pred = model.predict([X_test_genres, X_test_authors, X_test_book_format, X_test_book_pages,\n                           X_test_book_review_count,X_test_book_rating_count]).flatten()\n\n    #test['Fold_'+str(Fold)] = 0\n    test['Fold_'+str(Fold)] = Scaler.inverse_transform(pred.reshape(-1,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_squared_error(data['pred'], Scaler.inverse_transform(y.reshape(-1,1)))**0.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_squared_error(data['pred_lgbm'],\n                   Scaler.inverse_transform(y.reshape(-1,1)))**0.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#0.24227946566752415\n#0.22726323228988762","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['pred_keras'] = test[['Fold_'+str(fold) for fold in range(Fold+1)]].mean(axis=1)\ntest['pred_lgbm'] = test[['Fold_lgbm_'+str(fold) for fold in range(Fold+1)]].mean(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['pred'] = (test.pred_keras+test.pred_lgbm)/2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.book_rating = test['pred']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('same_aut.csv', index=False)","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}