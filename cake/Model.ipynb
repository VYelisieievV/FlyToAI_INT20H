{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nfrom sklearn import preprocessing\n\nimport lightgbm as lgb\n\nfrom keras.preprocessing.sequence import pad_sequences\nfrom sklearn.metrics import mean_squared_error\nnp.random.seed(42)\n\nfrom sklearn.model_selection import train_test_split\n\npd.options.mode.chained_assignment = None\n\n\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n\n\nfrom sklearn.model_selection import KFold\n\nimport tensorflow as tf\n\ntf.random.set_seed(1)\n\nfrom tensorflow.keras.layers import Input, Embedding, SpatialDropout1D, LSTM, Dropout, Dense\nfrom tensorflow.keras.layers import Concatenate,Flatten,Reshape, Bidirectional\nfrom tensorflow.keras.models import Model\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH = '/kaggle/input/predictingbookratingsint20h/'\ndata = pd.read_csv(PATH+'train.csv').drop(columns = 'id')\ntest = pd.read_csv(PATH+'test.csv').drop(columns = 'id')\nsubmission = pd.read_csv(PATH+'submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.iloc[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"book_genre\", \"book_authors\", \"book_format\", \"book_pages\", \"book_review_count\", \"book_rating_count\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_sep(data_):\n    data_.book_authors = data_.book_authors.fillna('')\n    data_.book_authors = data_.book_authors.apply(lambda x: x.split('|'))\n    \n    data_.book_genre = data_.book_genre.fillna('')\n    data_.book_genre = data_.book_genre.apply(lambda x: x.split('|'))\n    \n    return data_\n\ndata = split_sep(data)\ntest = split_sep(test)\n\ndef top5(data_):\n    data_['book_genre'] = data_['book_genre'].apply(lambda x: x[:5]  )\n    data_['book_authors'] = data_['book_authors'].apply(lambda x: x[0])\n    \n    return data_\n\ndata = top5(data)\ntest = top5(test)\n\ndef pp_format_pages(data_):\n    \n    data_[\"book_format\"] = data_[\"book_format\"].fillna(\"no_format\")\n    #fill nan with mean over format\n    data_[\"book_pages\"].loc[~data_[\"book_pages\"].isnull()] = (\n        data_[\"book_pages\"].loc[~data_[\"book_pages\"].isnull()].apply(lambda x: int(x[:-5]))\n    )\n    data_[\"book_pages\"] = data_[\"book_pages\"].astype(np.float32)\n    data_[\"book_pages\"] = data_[\"book_pages\"].fillna(\n        data_.groupby(\"book_format\")[\"book_pages\"].transform(\"mean\")\n    )\n    data_[\"book_pages\"] = data_[\"book_pages\"].fillna(0)\n    data_[\"book_pages\"] = data_[\"book_pages\"].astype(np.int32)\n    \n    return data_\n\ndata = pp_format_pages(data)\ntest = pp_format_pages(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('test book_rating_count 5% - ', test.book_rating_count.quantile(0.05))\nprint('Will lose', data[data.book_rating_count <= test.book_rating_count.quantile(0.05) ].shape[0]/data.shape[0])\n\ndata = data[data.book_rating_count > test.book_rating_count.quantile(0.05)]\ndata.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('% of common Authors in test',\n    data[data.book_authors.isin(test.book_authors.unique())].shape[0]/data.shape[0])\n\nprint('% of common Authors in train',\ntest[test.book_authors.isin(data.book_authors.unique())].shape[0]/test.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('Genres.json', 'w') as fp:\n    json.dump(Genres, fp)\n    \nwith open('Authors.json', 'w') as fp:\n    json.dump(Authors, fp)\n    \nwith open('Format.json', 'w') as fp:\n    json.dump(Format, fp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def flat(lst):\n    if isinstance(lst, list):\n        for item in lst:\n            yield from flat(item)\n    else:        \n        yield lst\n\nGenres = set(list(flat(list(test['book_genre']))))\nGenres = {i:ind+1 for ind, i in enumerate(Genres)}\n\nGenres.update({'not_in_test': max(Genres.values())+1})\n\n\nAuthors = set(list(flat(list(test['book_authors']))))\nAuthors = {i:ind for ind, i in enumerate(Authors)}\n\nAuthors.update({'not_in_test': max(Authors.values())+1})\n\nFormat = set(list(flat(list(test['book_format']))))\nFormat = {i:ind for ind, i in enumerate(Format)}\n\nFormat.update({'not_in_test': max(Format.values())+1})\n\n\ndef replace_smth(data_, Dict):\n    L = []\n    if type(data_)==list:\n        for i in data_:\n            if i in Dict.keys():\n                L.append(i)\n            else:\n                L.append('not_in_test')\n        return L\n    else:\n        if data_ in Dict.keys():\n            return data_\n        else:\n            return 'not_in_test'\n    \n\ndef replace_smth_data(data__):\n    data__['book_genre'] = data__['book_genre'].apply(lambda x: replace_smth(x, Genres))\n    data__['book_authors'] = data__['book_authors'].apply(lambda x: replace_smth(x, Authors))\n    data__['book_format'] = data__['book_format'].apply(lambda x: replace_smth(x, Format))\n\n    data__['book_genre'] = data__['book_genre'].apply(lambda x: [Genres[i] for i in x])\n    data__['book_authors'] = data__['book_authors'].apply(lambda x: Authors[x])\n    data__['book_format'] = data__['book_format'].apply(lambda x: Format[x])\n    \n    #data__['book_genre'] = list(pad_sequences(data__['book_genre'], maxlen=5, padding='post'))\n\n\n    return data__\n\ndata = replace_smth_data(data)\ntest = replace_smth_data(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.book_genre.apply(lambda x: [i for i in range])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#data = data[data.book_authors != 'not_in_test']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install langdetect\nfrom langdetect import detect\n\nfrom tqdm import tqdm\n\ndata = data[~data.book_desc.apply(lambda x: x[:len('http://')]=='http://') ]\ndata.reset_index(drop=True, inplace=True)\n\ndata['language'] = ''\nfor i in tqdm(range(0, data.shape[0], 100)):\n    try:\n        #print(i)\n        data['language'].iloc[i:i+100] = data.book_desc.iloc[i:i+100].apply(lambda x: detect(x[:50]))\n        \n    except:\n        pass\n        \ndata = data[(data['language'] == 'en') | (data['language'] == '')]\ndata.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Scaler = preprocessing.MinMaxScaler()\ndata.book_rating = Scaler.fit_transform(data.book_rating.values.reshape(-1,1))\n#test.book_rating = Scaler.transform(test.book_rating.values.reshape(-1,1))\n\nScaler_pag = preprocessing.MinMaxScaler()\ndata.book_pages = Scaler_pag.fit_transform(data.book_pages.values.reshape(-1,1))\ntest.book_pages = Scaler_pag.transform(test.book_pages.values.reshape(-1,1))\n\nScaler_rev = preprocessing.MinMaxScaler()\ndata.book_review_count = Scaler_rev.fit_transform(data.book_review_count.values.reshape(-1,1))\ntest.book_review_count = Scaler_rev.transform(test.book_review_count.values.reshape(-1,1))\n\nScaler_rat = preprocessing.MinMaxScaler()\ndata.book_rating_count = Scaler_rat.fit_transform(data.book_rating_count.values.reshape(-1,1))\ntest.book_rating_count = Scaler_rat.transform(test.book_rating_count.values.reshape(-1,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def SaveModel(filename, model, PATH=''):\n    joblib_file = PATH + filename+\".pkl\"  \n    joblib.dump(model, joblib_file)\n    \ndef LoadModel (filename, PATH =''):\n    return joblib.load(PATH + filename)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import joblib","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#SaveModel('Scaler', Scaler)\n#SaveModel('Scaler_pag', Scaler_pag)\n#SaveModel('Scaler_rev', Scaler_rev)\n#SaveModel('Scaler_rat', Scaler_rat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_genres = np.stack(data.book_genre.values)\nX_authors = data.book_authors.values\nX_book_format = data.book_format.values\nX_book_pages = data.book_pages.values\nX_book_review_count = data.book_review_count.values\nX_book_rating_count = data.book_rating_count.values\n\ny = data.book_rating.values\n\nX_test_genres = np.stack(test.book_genre.values)\nX_test_authors = test.book_authors.values\nX_test_book_format = test.book_format.values\nX_test_book_pages = test.book_pages.values\nX_test_book_review_count = test.book_review_count.values\nX_test_book_rating_count = test.book_rating_count.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Here all embed_size\nmax_features_authors = max(Authors.values())+1\nembed_size_authors = 100\n\nmax_features_genres = max(Genres.values())+1\nembed_size_genres = 50\n\nmax_features_format = max(Format.values())+1\nembed_size_format = 5\n\nprint(max_features_authors, max_features_genres, max_features_format)\n\ndef lstm128():\n    \n    inp_gen = Input(shape=(5,), name='genres')\n    inp_aut = Input(shape=(1,), name='authors')\n    inp_for = Input(shape=(1,), name='format')\n    inp_pag = Input(shape=(1,), name='pages')\n    inp_rev = Input(shape=(1,), name='review')\n    inp_rat = Input(shape=(1,), name='rating')\n    \n    inp = [inp_gen, inp_aut, inp_for, inp_pag, inp_rev, inp_rat]\n        \n    seq_gen   = Embedding(max_features_genres, embed_size_genres, name='emb_gen')(inp_gen)\n    seq_aut   = Embedding(max_features_authors, embed_size_authors, name='emb_aut')(inp_aut)\n    seq_for   = Embedding(max_features_format, embed_size_format, name='emb_for')(inp_for)\n    \n    lstm_gen  = LSTM(128, return_sequences=False )(seq_gen  )\n    lstm_aut  = LSTM(128, return_sequences=False )(seq_aut )\n    lstm_for  = LSTM(16, return_sequences=False )(seq_for )\n            \n    x = Concatenate(name=\"x1\")([lstm_gen, lstm_aut,lstm_for, inp_pag, inp_rev, inp_rat])\n\n    x = Dense(128, activation=\"relu\")(x)\n    x = Dropout(0.1)(x)\n    x = Dense(128, activation=\"relu\")(x)\n    x = Dropout(0.1)(x)\n    outp = Dense(1, activation=\"relu\")(x)\n    \n    model = Model(inputs=inp, outputs=outp)\n    \n    model.compile(loss='mse',\n                  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n                 )\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def early_stopping_lgb(train_ , valid_, params_, params_stopping_, columns_):\n\n    train_dataset = lgb.Dataset( train_[columns_], label =train_.book_rating, free_raw_data=False)\n    valid_dataset = lgb.Dataset( valid_[columns_], label =valid_.book_rating, free_raw_data=False)\n\n    model = lgb.train(\n        params_,\n        train_dataset,\n        num_boost_round = params_stopping_['num_boost_round'],\n        valid_sets = (train_dataset, valid_dataset) ,\n        early_stopping_rounds = params_stopping_['early_stopping_rounds'],\n        verbose_eval = params_stopping_['verbose_eval'],\n    )\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for gen in range(5):\n    data['gen'+str(gen)] = data.book_genre.apply(lambda x: x[gen])\n    test['gen'+str(gen)] = test.book_genre.apply(lambda x: x[gen])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['pred_lgbm'] = 0\n\nfor Fold, (train_index, valid_index) in enumerate(KFold(n_splits=5, random_state=42, shuffle=True).split(data)):\n    \n    train, valid = data.iloc[train_index], data.iloc[valid_index]\n    \n    print(Fold, train.shape[0], valid.shape[0])\n    \n    \n    columns_lgb = ['book_authors', 'book_format', 'book_pages',\n               'book_review_count', 'book_rating_count', 'gen0', 'gen1', 'gen2', 'gen3', 'gen4']\n\n    params = {'metrics':'l2',\n         'objective':'regression',\n              'num_leaves':256\n             }\n\n    params_stopping = {\n        'num_boost_round':10000,\n        'early_stopping_rounds':100,\n        'verbose_eval':1000}\n    \n    lgbm_train, lgbm_valid = train_test_split(train, random_state=42,shuffle=True, test_size=0.1)\n\n    model = early_stopping_lgb(lgbm_train, lgbm_valid, params, params_stopping, columns_lgb)\n    SaveModel('lgbm'+str(Fold), model)\n    \n    pred_valid = model.predict(valid[columns_lgb])\n    \n    data['pred_lgbm'].iloc[valid.index] =  Scaler.inverse_transform(pred_valid.reshape(-1,1)).flatten()\n    \n\n    pred = model.predict(test[columns_lgb])\n\n    test['Fold_lgbm_'+str(Fold)] = Scaler.inverse_transform(pred.reshape(-1,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['pred'] = 0\n\nfor Fold, (train_index, valid_index) in enumerate(KFold(n_splits=5, random_state=42, shuffle=True).split(data)):\n    \n    train, valid = data.iloc[train_index], data.iloc[valid_index]\n    \n    print(Fold, train.shape[0], valid.shape[0])\n    \n    \n    model = lstm128()\n\n    es = EarlyStopping( monitor='val_loss',\n                       patience=10)\n\n    reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n                                  factor=0.5,\n                                  patience=10,\n                                  min_lr=0.000001)\n\n    model.fit([X_genres[train.index], X_authors[train.index], X_book_format[train.index],\n               X_book_pages[train.index], X_book_review_count[train.index], X_book_rating_count[train.index]],\n               y[train.index], batch_size=3000, epochs=100, verbose=True,\n               validation_split=0.1, shuffle=True, \n               callbacks=[es,reduce_lr])\n    \n    model.save('keras'+str(Fold))\n\n\n    pred_valid = model.predict([X_genres[valid.index], X_authors[valid.index], X_book_format[valid.index],\n                  X_book_pages[valid.index], X_book_review_count[valid.index], X_book_rating_count[valid.index]])\n    \n    data['pred'].iloc[valid.index] =  Scaler.inverse_transform(pred_valid).flatten()\n    \n    \n    \n    pred = model.predict([X_test_genres, X_test_authors, X_test_book_format, X_test_book_pages,\n                           X_test_book_review_count,X_test_book_rating_count]).flatten()\n\n    #test['Fold_'+str(Fold)] = 0\n    test['Fold_'+str(Fold)] = Scaler.inverse_transform(pred.reshape(-1,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_squared_error(data['pred'], Scaler.inverse_transform(y.reshape(-1,1)))**0.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_squared_error(data['pred_lgbm'],\n                   Scaler.inverse_transform(y.reshape(-1,1)))**0.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#0.24227946566752415\n#0.22726323228988762","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['pred_keras'] = test[['Fold_'+str(fold) for fold in range(Fold+1)]].mean(axis=1)\ntest['pred_lgbm'] = test[['Fold_lgbm_'+str(fold) for fold in range(Fold+1)]].mean(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['pred'] = (test.pred_keras+test.pred_lgbm)/2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.book_rating = test['pred']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('same_aut.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}